---
title: 'Kickstarter. Análisis de proyectos de crowfunding'
author: "Adam Kepa"
date: "28 de mayo de 2019"
output:
  html_document:
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: true
    params: 
      output_dir: "../pdf"
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
library(dplyr)
library(janitor)
library(randomForest)
library(ggplot2)
library(gmodels)
library(goft)
library(qualityTools)
library(EnvStats)
library(DescTools)
library(FSA)

```

# Introducción
## Descripción del dataset

Para esta práctica se ha elegido el set de datos [Kickstarter Projects](https://www.kaggle.com/kemical/kickstarter-projects) de Kaggle, con datos relativos a iniciativas que buscan financiación en la página [Kickstarter.com](https://www.kickstarter.com/).

Es un set de datos interesantes por el gran volumen de observaciones (más de 300K), y que se asemeja al volumen del que de datos que se puede manejar en proyectos reales de ciencia de datos. Por otro lado, es interesante por ser un set relativamente actual y por las variables disponibles. Éstas son tanto cuantitativas como cualitativas, y alguna de ellas tienen un número alto de categorías.

El listado completo de variables es el siguiente:

1. __ID__. Numérico. Identificador de la iniciativa.
2. __Name__. Categórico. Nombre de la iniciativa.
3. __Main category__. Categórico. Categoría de la iniciativa (nivel 1).
4. __Category__. Categórico. Categoría de la iniciativa (nivel 2).
5. __Currency__. Categórico. Moneda en la que se realiza la recaudación.
6. __Deadline__. Fecha. Fecha en la que acaba la recaudación.
7. __Goal__. Numérico. Cantidad de dinero que se intenta recaudar. 
8. __Launched__. Timestamp. Fecha y hora en la que se inició la iniciativa. 
9. __Pledged__. Numérico. Dinero recaudado al cumplirse la fecha de fin. 
10. __Backers__. Numérico. Número de patrocinadores que han participado en la iniciativa
11. __Country__. Categórico. País de origen de la iniciativa.
12. __USD Pledged__. Numérico. Conversión de la variable _Pledged_ a la divisa USD, realizado por Kickstarter.com
13. __USD Pledged Real__. Numérico. Conversión de la variable _Pledged_ a la divisa USD, realizado por el autor del dataset.
14. __USD Goal Real__. Numérico. Conversión de la variable _Goal_ a la divisa USD, realizado por el autor del dataset.

Este estado final de una iniciativa se indica en el campo state: 

1. __state__. Categórico. Resultado de la iniciativa al finalizar el plazo. 

__El objetivo del análisis será tratar de entender qué variables tienen un impacto significativo en el resultado final o en la cantidad de dinero que consigue reunir un proyecto__.

### Carga de datos

Realizamos la carga de datos. En este caso, y puesto que tenemos variables de tipo fecha, vamos a cargar las variables categóricas como strings para realizar la conversión al tipo esperado a posteriori.

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
path <- "../csv/ks-projects-201801.csv"
original <- read.csv(path, header=T,sep=",", encoding = "UTF-8", stringsAsFactors=FALSE)

glimpse(original)

original$launched <- as.Date(original$launched)
original$deadline <- as.Date(original$deadline)
original$category <- as.factor(original$category)
original$main_category <- as.factor(original$main_category)
original$currency <- as.factor(original$currency)
original$state <- as.factor(original$state)
original$country <- as.factor(original$country)
```

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
glimpse(original)
```

## Selección de datos

En el listado de variables de la sección anterior vemos que el set de datos incluye información duplicada. La cantidad objetivo está disponible en la moneda original de la promoción (_Goal_), así como su conversión a USD (_USD Goal Real_). Por otro lado, la cantidad final recaudada está disponible en la divisa original (_Pledged_), la conversión a USD realizada por la plataforma (_USD Pledged_), y la conversión a USD realizada por el autor del set de datos (_USD Pledged Real_). Puesto que la información de estas variables es redundante, se va a mantener únicamente la versión estandarizada de estos datos. Esto es, la conversión de las dos variables realizadas por el autor del set de datos. 

Por otro lado, para realizar la analítica de datos no son necesarios los campos que identifican las observaciones (_ID_ y _Name_).

Finalmente, y puesto que no se va a realizar un análisis de series temporales, se puede descartar las variables de tipo fecha (_Launched_ y _Deadline_). Sin embargo, a partir de estas variables es posible derivar un nuevo campo que podría tener influencia en el resultado de la recaudación de fondos: la duración de la campaña. 

Vamos a derivar este dato, y a elmininar las variables innecesarias. Estas modificaciones se realizarán sobre una copia del set original, por si fuese necesario realizar alguna comprobación sobre este set más adelante. 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# Copia del set de datos
mydata <- original
# Derivación de la duración
mydata$duration_tmp <- mydata$deadline - mydata$launched
mydata$duration <- as.numeric(mydata$duration_tmp, units="days")
original$duration <- as.numeric(mydata$duration_tmp, units="days")
# Borrado de las variables innecesarias
mydata <- dplyr::select(mydata, -ID, -name, -goal, -pledged, -usd.pledged, -launched, -deadline, -duration_tmp)
# Resumen de los datos seleccionados
```

Finalmente, también puede ser interesante comprobar si una iniciativa ha conseguido recaudar el dinero que se proponía:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata$goal_reached <- mydata$usd_pledged_real >= mydata$usd_goal_real
```

Como se puede observar en la tabla siguiente, se ha reducido el set a nueve inputs y la etiqueta de clase:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
glimpse(mydata)
```

# Limpieza de datos
## Valores perdidos

En primer lugar, vamos a comprobar si existen observaciones con el valor NA en alguna variable:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
colSums(is.na(mydata))
```

Vemos que no existen valores sin imputar. Vamos a comprobar también cuales son los posibles valores de las variables de tipo "Factor" para comprobar si los valores nulos se han reemplazado por alguna etiqueta:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
unique(mydata$category)
unique(mydata$main_category)
unique(mydata$currency)
unique(mydata$state)
unique(mydata$country)
```

Vemos que la etiqueta de clase (variable _state_) tiene seis posibles valores entre los que se encuentran "undefined" y "live". El primero se corresponde a una etiqueta que se ha dado a los valores perdidos, y el segundo a campañas que estaban en activo cuando se hizo la recopilación de datos. Las observaciones de este segundo caso no aportan valor para predecir el resultado de una campaña al tratarse de observaciones de campañas no finalizadas, y por tanto habrá que eliminarlas. En cuanto al primer caso, sería posible imputar valores o eliminar también las observaciones asociadas. Para decidir entre una u otra, vamos a comprobar el porcentaje de observaciones de esta clase en una tabla de frecuencias:

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata$state)
```

Las observaciones con estado _"undefined"_ suponen menos del 1% del total. Por ello, y por el hecho de que el número total de observaciones es muy amplio, vamos a eliminar las observaciones asociadas:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata <- subset(mydata, state != "undefined" & state != "live")
# Creamos un factor nuevo para elminar las categorías descartadas
mydata$state <- as.factor(as.character(mydata$state))
# Tabla de frecuencias después del ajuste
tabyl(mydata$state)
```

Por otro lado, vemos que existe un valor anómalo ("N,0\") en la variable country. Este valor probablemente se deba a un error a la hora de hacer el scrapping de los datos. Comprobamos el número de observaciones afectadas:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
nrow(subset(mydata, (country == "N,0\"")))
```

Y procedemos de forma análoga a la anterior: el número de observaciones afectadas es despreciable comparado con el total, y por tanto se pueden descartar sin problemas:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata <- subset(mydata, (country != "N,0\""))
# Creamos un factor nuevo para elminar la categoría incorrecta
mydata$country <- as.factor(as.character(mydata$country))
```

Para el resto de variables cualitativas no se observa ningún valor que pueda representar un valor perdido o erróneo. 

## Valores extremos

Vamos a analizar las variables cuantitativas en búsqueda de valores extremos. 

### Patrocinadores (backers)

Esta variable representa al número de patrocinadores que han aportado dinero a la iniciativa.  Vamos a comprobar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$backers)
par(mfrow=c(1,2))
hist(mydata$backers)
boxplot(mydata$backers)
```

Vemos que existen valores muy extremos. El 75% de los datos (3er cuartil) está por debajo de 57 patrocinadores. Sin embargo, existen valores superiores a 200000. Vamos a comprobar a cuantas iniciativas han contribuído más de 100000 personas:
```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
nrow(subset(mydata, backers > 100000))
```

Comprobamos estas observaciones en el set original:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
subset(original, backers > 100000)
```

Acudiendo a Kickstarter, comprobamos que estos valores son correctos, y que se corresponden a las iniciativas que históricamente han tenido más exito en esta plataforma:

* [Fidget Cube: A Vinyl Desk Toy](https://www.kickstarter.com/projects/antsylabs/fidget-cube-a-vinyl-desk-toy?lang=es)
* [https://www.kickstarter.com/projects/elanlee/exploding-kittens?lang=es](https://www.kickstarter.com/projects/antsylabs/fidget-cube-a-vinyl-desk-toy?lang=es)
* [Bring Reading Rainbow Back for Every Child, Everywhere!](https://www.kickstarter.com/projects/readingrainbow/bring-reading-rainbow-back-for-every-child-everywh?lang=es)

Por tanto, son observaciones legítimas que no se deben descartar. Sin embargo, y por intuición, las iniciativas con un número alto de patrocinadores salen adelante. Vamos a identificar la observación con mayor número de patrocinadores que NO ha salido adelante:

```{r echo=TRUE, message=FALSE, warning=FALSE}
aux <- mydata[mydata$state != "successful",]
aux <- aux[order(-aux$backers),]
head(aux, n = 1)
```

Vamos a comprobar cuántas observaciones existen con un mayor número de patrocinadores (y que han salido adelante):

```{r echo=TRUE, message=FALSE, warning=FALSE}
nrow(mydata[mydata$backers > 20632,])
```

Únicamente 76. Esto quiere decir que imputando el valor 20632 a todas estas observaciones obtendríamos el mismo resultado y eliminaríamos valores extremos. Sin embargo, para valores inferiores, seguramente la frecuencia de las iniciativas que han tenido éxito es mucho superior al resto de resultados:

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata[mydata$backers > 100,]$state)
tabyl(mydata[mydata$backers > 250,]$state)
tabyl(mydata[mydata$backers > 500,]$state)
tabyl(mydata[mydata$backers > 1000,]$state)
tabyl(mydata[mydata$backers > 2000,]$state)
```

Vemos que a partir de 1000 patrocinadores, la frecuencia de éxito es de prácticamente un 95%. Por tanto, si imputamos el 1000 como valor máximo al número de patrocinadores conseguiremos eliminar valores extremos sin apenas pérdida de información. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
nrow(mydata[mydata$backers > 1000,])
mydata <- within(mydata, backers[backers > 1000] <- 1000)
```

Volvemos a comprobar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(mydata$backers)
par(mfrow=c(1,2))
hist(mydata$backers)
boxplot(mydata$backers)
```

Vemos que de esta forma sigue habiendo valores extremos. Sin embargo, esto probablemente se deba a que los datos no siguen una distribución normal. Aplicando el logaritmo se puede comprobar que no existen datos fuera del rango intercuartílico:

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(log(mydata$backers))
par(mfrow=c(1,2))
hist(log(mydata$backers))
boxplot(log(mydata$backers))
```

### Cantidad objetivo (usd_goal_real)

Esta variable representa la cantidad que tienen como objetivo recaudar los proyectos. Vamos a observar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$usd_goal_real)

par(mfrow=c(1,2))
hist(mydata$usd_goal_real)
boxplot(mydata$usd_goal_real)
```

Vemos que en este caso también existen valores extremos. Comprobamos las observaciones asociadas:

```{r echo=TRUE, message=FALSE, warning=FALSE}
aux <- original[order(-original$usd_goal_real),]
head(aux, n = 3)
```

De forma análoga a la variable de _backers_, acudimos a Kickstarter para verificar que, efectivamente, son iniciativas que intentaron recaudar esa cantidad de dinero:

* [FUCK Potato Salad. Paleo Potato Brownies!](https://www.kickstarter.com/projects/2095375022/fuck-potato-salad-lets-bake-potato-brownies?ref=category_location)
* [A Celtic Lovestory](https://www.kickstarter.com/projects/245190432/a-celtic-lovestory?ref=category)
* [Hydroponic's Skyscraper](https://www.kickstarter.com/projects/2099347793/hydroponics-skyscraperun-gratte-ciel-hydroponiquee?ref=category_location)

Dado que aparenemente son proyectos que se crearon como broma, probablemente podemos eliminar valores extremos de la misma forma que hemos hecho con la variable anterior. Vamos a comprobar la frecuencia con de los resultados, filtrando por la cantidad objetivo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata[mydata$usd_goal_real > 100000,]$state)
tabyl(mydata[mydata$usd_goal_real > 1000000,]$state)
tabyl(mydata[mydata$usd_goal_real > 10000000,]$state)
tabyl(mydata[mydata$usd_goal_real > 50000000,]$state)
```

En este caso no observamos un patrón tan significativo como en la variable anterior, por lo que no se realizará la imputación de un valor máximo para evitar la pérdida de información. 

### Cantidad recaudada (usd_pledged_real)

Esta variable es la candidad de dinero recaudado para poder realizar el proyecto. Vamos a comprobar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$usd_pledged_real)
par(mfrow=c(1,2))
hist(mydata$usd_pledged_real)
boxplot(mydata$usd_pledged_real)
```

Al igual que en el caso anterior, también existen valore extremos (basta con observar la gran diferencia entre la media, la mediana y el valor máximo). Vamos a extraer las observaciones con los valores más altos de esta variable: 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
aux <- original[order(-original$usd_pledged_real),]
head(aux, n = 2)
```

Acudiendo a Kickstarter vemos que estos valores extremos son correctos y se corresponden también a proyectos con mucho éxito. 

Vemos si es posible imputar un valor máximo:

* [Pebble Time - Awesome Smartwatch](https://www.kickstarter.com/projects/getpebble/pebble-time-awesome-smartwatch-no-compromises?lang=es)
* [COOLEST COOLER](https://www.kickstarter.com/projects/ryangrepper/coolest-cooler-21st-century-cooler-thats-actually?lang=es)

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata[mydata$usd_pledged_real > 10000,]$state)
tabyl(mydata[mydata$usd_pledged_real > 100000,]$state)

```

A partir de 100000 USD recaudados, el 95% de los proyectos acaban con éxito, por lo que podemos imputar este valor máximo para reducir los valores extremos sin perder apenas información en los datos:

```{r echo=TRUE, message=FALSE, warning=FALSE}
nrow(mydata[mydata$usd_pledged_real > 100000,])
mydata <- within(mydata, usd_pledged_real[usd_pledged_real > 100000] <- 100000)
```

Volvemos a visualizar los datos, y vemos que no parecen ajustarse a una distribución normal:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$usd_pledged_real)

par(mfrow=c(1,2))
hist(mydata$usd_pledged_real)
boxplot(mydata$usd_pledged_real)
```

Sin embargo, en el caso de aplicar el logaritmo, la distribución se asemeja a lo que podría ser una normal, con un aumento de frecuencia en el valor 0. 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(log(mydata$usd_pledged_real))

par(mfrow=c(1,2))
hist(log(mydata$usd_pledged_real))
boxplot(log(mydata$usd_pledged_real))
```

### Duración campaña (duration)
Vamos a comprobar la distribución de valores de la variable derivada al inicio:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$duration)

par(mfrow=c(1,2))
hist(mydata$duration)
boxplot(mydata$duration)
```

Vemos que en este caso también existen valores muy extremos. El valor máximo son 16739 días (45 años), lo que supone que se trata de un valor erróneo. Vamos a comprobar cuantas iniciativas hay con más 100 días de duración:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
nrow(subset(mydata, duration > 100))
```

Únicamente 7, por lo que probablemente se deba a un error en los datos iniciales o en el cálculo de la variable. Para comprobarlo, vamos a examinar las observaciones asociadas en el set de datos inicial:

```{r echo=TRUE, message=FALSE, warning=FALSE}
subset(original, duration > 100)
```

Vemos que el error se debe a que la fecha de inicio de algunas iniciativas está mal informada (1970-01-01). Se trata del valor inicial del formato [epoch](https://en.wikipedia.org/wiki/Unix_time), por lo que seguramente se trate de valores perdidos. Eliminamos estas observaciones, y volvemos a analizar la distribución de valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# Eliminamos observaciones con valores incorrectos
mydata <- subset(mydata, duration < 100)

summary(mydata$duration)

par(mfrow=c(1,2))
hist(mydata$duration)
boxplot(mydata$duration)
```

Vemos que ahora existen valores extremos, pero correctos: la campaña más larga se situa en torno a los 3 meses, mientras que tanto el valor medio como el mediano están en torno a un mes. 

# Análisis de datos

## Análisis de normalidad

En el apartado de valores extremos se ha comprobado a simple vista que las variables no siguen una distribución normal. Sin embargo, dada la forma del histograma es posible que sigan una distribución LogNormal o exponencial. 
Para ello, visualizamos en primer lugar el histograma del logaritmo de estas variables:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
par(mfrow=c(1,2))
hist(log(mydata$backers), main = "Backers")
hist(log(mydata$duration), main = "Duration")
hist(log(mydata$usd_pledged_real), main = "Pledged")
hist(log(mydata$usd_goal_real), main = "Goal")

summary(log(dplyr::select(mydata, backers, duration, usd_pledged_real, usd_goal_real)))
```

Backers y Duration claramente no siguen una distribución LogNormal, por lo que no es necesario aplicar ningún test. En cuanto a las variables Pledged y Goal, vamos a aplicar el test de [Test de Shapiro-Wilk](https://es.wikipedia.org/wiki/Test_de_Shapiro%E2%80%93Wilk) y a observar los diagramas QQ para validar si estas variables sí que siguen esta distribución. 

Sin embargo, dado que estas variables contienen el valor 0, antes de aplicar el logaritmo vamos a imputar un valor mínimo, puesto de lo contrario no se podría aplicar el tests al tener valores inválidos. Por otro lado, la implementación en R del test acepta como máximo 5000 observaciones, que obtendremos a partir de la muestra original por muestreo aleatorio. 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata <- within(mydata, usd_goal_real[usd_goal_real <= 0] <- 0.00001)
mydata <- within(mydata, usd_pledged_real[usd_pledged_real <= 0] <- 0.00001)

set.seed(123)
sample <- mydata[sample(1:nrow(mydata), 5000, replace=FALSE),]
```

Comprobamos la variable Goal:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# Goal
summary(log(sample$usd_goal_real))
shapiro.test(log(sample$usd_goal_real))
qqnorm(log(sample$usd_goal_real))
```

Comprobamos la variable Pledged:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# Pledged
summary(log(sample$usd_pledged_real))
shapiro.test(log(sample$usd_pledged_real))
qqnorm(log(sample$usd_pledged_real))
```

Y vemos que en ambos casos, el p-value obtenido en el test es cercano a 0, por lo que se rechaza la hipótesis nula de que las variables siguen una distribución normal, y se acepta la alternativa (es decir, que no siguen una distribución normal, o log-normal en este caso). Esto se corrobora con el diagrama QQ, en el que se ve que la distribución no se ajusta a la diagonal. 

Dado este resultado, no ampoco se realizará [la transformación de Box-Cox](https://es.wikipedia.org/wiki/Transformaci%C3%B3n_Box-Cox) al estar los datos muy alejados de una distribución normal, por lo que a la hora de realizar el análisis de los datos se aplicará algoritmos no paramétricos.

## Selección de datos

Para seleccionar los datos sobre los que vamos a realizar el análisis, vamos a realizar un análisis previo de correlación para ver si es posible reducir la dimensionalidad descartando algunas de las variables que no son independientes.  

Vamos a proceder en primer lugar con las cuatro variables categóricas disponibles. 

En primer lugar, las variables "Category" y "Main Category" están correlacionadas por definición (la primera es un desglose de la segunda). Para realizar un análisis manual, vamos a quedarnos únicamente con la segunda, puesto que la primera tiene un número de valores posibles demasiado alto para ser manejable en un análisis no automatizado.

Por otro lado, las variables "Country" y "Currency" probablemente son dependientes. Vamos a realizar un 
test [chi-square](https://en.wikipedia.org/wiki/Chi-squared_test) para verificar si se puede obviar una de ellas en la fase de análisis. Planteamos las hipótesis, y supondremos un nivel de significación del 0.05:

$$H_{0}: \text{Las variables son independientes}$$ 

$$H_{1}:  \text{ Las variables NO son independientes}$$

Calculamos el p-value:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
t <- table(mydata$currency, mydata$country)
chisq.test(t ) 
```

Y vemos que el valor es prácticamente 0, por lo que rechazamos la hipótesis nula y aceptamos la alternativa. Esto es, que las variables no son independientes. Por ello, vamos a excluir la variable "Currency" de los datos a analizar.

Para las variables cuantitativas, vamos a calcular la matrix de correlación usando como método la correlación de Spearman, dado que las variables no se ajustan a una distribución normal:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
num_vars = dplyr::select(mydata, backers, country, usd_pledged_real, usd_goal_real, duration)
round(cor(x = data.matrix(num_vars), method = "spearman"), 3)
```

Vemos que el número de patrocinadores y el dinero recaudado tienen una relación de correlación positiva, lo que significa que éstas no son independientes y por tanto se podría obviar una de ellas a la hora de realiar el análisis de datos. 

Eliminamos del set de datos aquellas variables que no tendremos en cuenta para el análisis:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata <- dplyr::select(mydata, -currency, -category, -backers)
```

Por lo que para el análisis dispondremos de seis variables, y la etiqueta de clase:
```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
glimpse(mydata)

```

## Análisis descriptivo

En primer lugar comprobamos las frecuencias del resultado de los proyectos:



```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
tabyl(mydata$state)
```

Vemos que XXX. 

Vamos a comprobar si, a simple vista existen diferencias significativas en la tendencia central y en la dispersión del dinero recaudado en función de la categoría del proyecto.

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
ggplot(data = mydata, aes(x=mydata$main_category, y=log(mydata$usd_pledged_real))) + stat_boxplot(geom ='errorbar') + geom_boxplot(aes(fill=main_category)) + ggtitle("Dinero recaudado (log) por categoría") + xlab("Categoría") + ylab("Dinero recaudado")
```


```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
ggplot(data = mydata, aes(x=mydata$state, y=log(mydata$usd_goal_real))) + stat_boxplot(geom ='errorbar') + geom_boxplot(aes(fill=state)) + ggtitle("Dinero recaudado (log) por categoría") + xlab("Categoría") + ylab("Dinero recaudado")
```

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
ggplot(data = mydata, aes(x=mydata$goal_reached, y=mydata$duration)) + stat_boxplot(geom ='errorbar') + geom_boxplot(aes(fill=goal_reached)) + ggtitle("Dinero recaudado (log) por categoría") + xlab("Categoría") + ylab("Dinero recaudado")
```




En base a este análisis, podemos plantear las siguientes pruebas:
* 
* Aparentemente existen diferencias en las cantidades que recaudan los proyectos en función de la categoría. ¿






## Análisis inferencial
### Duración

Vamos a comprobar si existe una diferencia significativa en la duración de los proyectos, entre aquellos proyectos que llegan a recaudar la cantidad objetivo, y aquellos que no. Como se ha podido observar en el boxplot de apartado de análisis descriptivo, las tendencias centrales son similares:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
reached <- mydata[mydata$goal_reached == TRUE,]$duration
not_reached <- mydata[mydata$goal_reached == FALSE,]$duration

# Medias
mean(reached)
mean(not_reached)
# Medianas
median(reached)
median(not_reached)
```

Dado que la variable duration no sigue una distribución normal, no es posible el empleo del test T. Por ello, vamos a usar el [test de Wilcoxon](https://es.wikipedia.org/wiki/Prueba_de_los_rangos_con_signo_de_Wilcoxon), que es la alternativa no paramétrica al anterior. Suponemos un nivel de significación del 0.05 y las hipótesis siguientes:

$$H_{0}: \mu_{Reached} = \mu_{Not Reached} $$

$$H_{1}: \mu_{Reached} \ne \mu_{Not Reached} $$ 


```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}

wilcox.test(reached, not_reached, paired = FALSE, alternative = "two.sided")
```

El p-value obtenido es cercano a 0, por lo que rechazaremos la hipótesis nula y aceptaremos la alternativa. Esto es, que la duración si que es distinta dependiendo de si un proyecto logra alcanzar la cantidad objetivo. 

### Dinero recaudado por categoría 

Vamos a probar si hay diferencias significativas en las cantidades medias recaudadas dependiendo del tipo de proyecto. Dado que hemos visto que los datos no siguen una distribución normal no podemos aplicar un análisis de varianza unifactorial (ANOVA), por lo que aplicaremos el test no paramétrico [Kruskal-Wallis](https://es.wikipedia.org/wiki/Prueba_de_Kruskal-Wallis) para comprobar si las medias de todas las categorías son iguales. Planteamos la hipótesis nula y alternativa, y suponemos un nivel de significación del 0.05:

$$H_{0}: \text{Todas las medias son iguales}$$ 

$$H_{1}:  \text{No todas las medias son iguales}$$

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata$usd_pledged_real_log <- log(mydata$usd_pledged_real)
kruskal.test(usd_pledged_real_log~main_category, data=mydata)
```

Obtenemos un p-value cercano a cero, por lo que rechazamos la hipótesis nula: existe al menos alguna media significativamente distinta de las demás. 

Para comprobar qué medias difieren significativamente de las demás vamos a aplicar el [test post hoc de Dunn](https://www.statisticshowto.datasciencecentral.com/dunns-test/). Este test no paramétrico permite realizar comparaciones múltiples, y es adecuado para muestras en las que los distintos grupos tienen un número distinto de observaciones como en este caso (REF1).

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
dunn_res <- dunnTest(usd_pledged_real_log~main_category,data=mydata,method="by")
print(dunn_res,dunn.test.results=TRUE)
```

En la tabla anterior vemos el p-value asociado a la compración entre todos los pares de grupos. En esta comparación vemos que todas las medias son significativamente distintas salvo las de los siguientes pares de grupos:

* Dance - Comics
* Dance - Games
* Journalism - Crafts
* Publishing - Fashion
* Theater - Dance
* Theater - Games

# Conclusión

A lo largo de esta práctica se ha podido obtener una serie de resultados que permiten entender la naturaleza de los proyectos de crowfunding.

En primer lugar, durante la búsqueda de valores extremos se ha podido observar que existen proyectos con muchísimo más éxito (en cuanto a patrocinadores y dinero recaudado) que los demás, y cuyos valores se han tenido que suavizar para que no influyesen a la hora de aplicar la analítica de datos. 

Por otro lado se ha podido comprobar que ninguna de las variables cuantitativas se ajusta a una distribución normal o log-normal, a pesar de que la distribución de valores sigue una curva similar a la gausiana aplicando el logaritmo sobre los valores reales. 

El hecho de que ninguna de las variables siguiese una distribución normal ha obligado al uso de tests no paramétricos (y de menor poder estadístico) en la fase de analítica. 

Como resultados destacables cabría mencionar que se ha podido observar que [TODO]

Sin embargo, y como se ha comentado, la parte analítica de la práctica se ha visto impactada por la falta de conocimiento sobre cómo trabajar con datos que no siguen una distribución conocida. 

# Referencias y bibliografía
(Falta completar)
(1)  https://rcompanion.org/rcompanion/d_06.html

