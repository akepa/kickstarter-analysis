---
title: 'Kickstarter. Análisis de proyectos de crowfunding'
author: "Adam Kepa"
date: "28 de mayo de 2019"
output:
  html_document:
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
    toc_float: true
    params: 
      output_dir: "../pdf"
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
library(dplyr)
library(janitor)
library(randomForest)
library(ggplot2)
library(gmodels)
library(goft)
library(qualityTools)
library(EnvStats)
library(DescTools)
#library(MASS)

```

# Introducción
## Descripción del dataset

Para esta práctica se ha elegido el set de datos [Kickstarter Projects](https://www.kaggle.com/kemical/kickstarter-projects) de Kaggle, con datos relativos a iniciativas que buscan financiación en la página [Kickstarter.com](https://www.kickstarter.com/).

Es un set de datos interesantes por el gran volumen de observaciones (más de 300K), y que se asemeja al volumen del que de datos que se puede manejar en proyectos reales de ciencia de datos. Por otro lado, es interesante por ser un set relativamente actual y por las variables disponibles. Éstas son tanto cuantitativas como cualitativas, y alguna de ellas tienen un número alto de categorías.

El listado completo de variables es el siguiente:

1. __ID__. Numérico. Identificador de la iniciativa.
2. __Name__. Categórico. Nombre de la iniciativa.
3. __Main category__. Categórico. Categoría de la iniciativa (nivel 1).
4. __Category__. Categórico. Categoría de la iniciativa (nivel 2).
5. __Currency__. Categórico. Moneda en la que se realiza la recaudación.
6. __Deadline__. Fecha. Fecha en la que acaba la recaudación.
7. __Goal__. Numérico. Cantidad de dinero que se intenta recaudar. 
8. __Launched__. Timestamp. Fecha y hora en la que se inició la iniciativa. 
9. __Pledged__. Numérico. Dinero recaudado al cumplirse la fecha de fin. 
10. __Backers__. Numérico. Número de patrocinadores que han participado en la iniciativa
11. __Country__. Categórico. País de origen de la iniciativa.
12. __USD Pledged__. Numérico. Conversión de la variable _Pledged_ a la divisa USD, realizado por Kickstarter.com
13. __USD Pledged Real__. Numérico. Conversión de la variable _Pledged_ a la divisa USD, realizado por el autor del dataset.
14. __USD Goal Real__. Numérico. Conversión de la variable _Goal_ a la divisa USD, realizado por el autor del dataset.

Este estado final de una iniciativa se indica en el campo state: 

1. __state__. Categórico. Resultado de la iniciativa al finalizar el plazo. 

__El objetivo de este set de datos es intentar predecir el estado final de una iniciativa a partir de los predictores mencionados anteriormente. Para ello, el primer paso (y el problema que trataremos de resolver con esta práctica), es tratar de descubrir si existen diferencias significativas de los predictores asociadas a los distintos estados de los proyectos__.


### Carga de datos

Realizamos la carga de datos. En este caso, y puesto que tenemos variables de tipo fecha, vamos a cargar las variables categóricas como strings para realizar la conversión al tipo esperado a posteriori.

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
path <- "../csv/ks-projects-201801.csv"
original <- read.csv(path, header=T,sep=",", encoding = "UTF-8", stringsAsFactors=FALSE)

glimpse(original)

original$launched <- as.Date(original$launched)
original$deadline <- as.Date(original$deadline)
original$category <- as.factor(original$category)
original$main_category <- as.factor(original$main_category)
original$currency <- as.factor(original$currency)
original$state <- as.factor(original$state)
original$country <- as.factor(original$country)
```

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
glimpse(original)
```

## Selección de datos

En el listado de variables de la sección anterior vemos que el set de datos incluye información duplicada. La cantidad objetivo está disponible en la moneda original de la promoción (_Goal_), así como su conversión a USD (_USD Goal Real_). Por otro lado, la cantidad final recaudada está disponible en la divisa original (_Pledged_), la conversión a USD realizada por la plataforma (_USD Pledged_), y la conversión a USD realizada por el autor del set de datos (_USD Goal Real_). Puesto que la información de estas variables es redundante, se va a mantener únicamente la versión estandarizada de estos datos. Esto es, la conversión de las dos variables realizadas por el autor del set de datos. 

Por otro lado, para realizar la analítica de datos no son necesarios los campos que identifican las observaciones (_ID_ y _Name_).

Finalmente, y puesto que no se va a realizar un análisis de series temporales, se puede descartar las variables de tipo fecha (_Launched_ y _Deadline_). Sin embargo, a partir de estas variables es posible derivar un nuevo campo que podría tener influencia en el resultado de la recaudación de fondos: la duración de la campaña. 

Vamos a derivar este dato, y a elmininar las variables innecesarias. Estas modificaciones se realizarán sobre una copia del set original, por si fuese necesario realizar alguna comprobación sobre este set más adelante. 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# Copia del set de datos
mydata <- original
# Derivación de la duración
mydata$duration_tmp <- mydata$deadline - mydata$launched
mydata$duration <- as.numeric(mydata$duration_tmp, units="days")
original$duration <- as.numeric(mydata$duration_tmp, units="days")
# Borrado de las variables innecesarias
mydata <- select(mydata, -ID, -name, -goal, -pledged, -usd.pledged, -launched, -deadline, -duration_tmp)
# Resumen de los datos seleccionados
glimpse(mydata)
```

Como se puede observar en la tabla anterior, se ha reducido el set a ocho inputs y la etiqueta de clase.

# Limpieza de datos
## Valores perdidos

En primer lugar, vamos a comprobar si existen observaciones con el valor NA en alguna variable:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
colSums(is.na(mydata))
```

Vemos que no existen valores sin imputar. Vamos a comprobar también cuales son los posibles valores de las variables de tipo "Factor" para comprobar si los valores nulos se han reemplazado por alguna etiqueta:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
unique(mydata$category)
unique(mydata$main_category)
unique(mydata$currency)
unique(mydata$state)
unique(mydata$country)
```

Vemos que la etiqueta de clase (variable _state_) tiene seis posibles valores entre los que se encuentran "undefined" y "live". El primero se corresponde a una etiqueta que se ha dado a los valores perdidos, y el segundo a campañas que estaban en activo cuando se hizo la recopilación de datos. Las observaciones de este segundo caso no aportan valor para predecir el resultado de una campaña al tratarse de observaciones de campañas no finalizadas, y por tanto habrá que eliminarlas. En cuanto al primer caso, sería posible imputar valores o eliminar también las observaciones asociadas. Para decidir entre una u otra, vamos a comprobar el porcentaje de observaciones de esta clase en una tabla de frecuencias:

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata$state)
```

Las observaciones con estado _"undefined"_ suponen menos del 1% del total. Por ello, y por el hecho de que el número total de observaciones es muy amplio, vamos a eliminar las observaciones asociadas:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata <- subset(mydata, state != "undefined" & state != "live")
# Creamos un factor nuevo para elminar las categorías descartadas
mydata$state <- as.factor(as.character(mydata$state))
# Tabla de frecuencias después del ajuste
tabyl(mydata$state)
```

Por otro lado, vemos que existe un valor anómalo ("N,0\") en la variable country. Este valor probablemente se deba a un error a la hora de hacer el scrapping de los datos. Comprobamos el número de observaciones afectadas:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
nrow(subset(mydata, (country == "N,0\"")))
```

Y procedemos de forma análoga a la anterior: el número de observaciones afectadas es despreciable comparado con el total, y por tanto se pueden descartar sin problemas:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
mydata <- subset(mydata, (country != "N,0\""))
# Creamos un factor nuevo para elminar la categoría incorrecta
mydata$country <- as.factor(as.character(mydata$country))
```

Para el resto de variables cualitativas no se observa ningún valor que pueda representar un valor perdido o erróneo. 

## Valores extremos

Vamos a analizar las variables cuantitativas en búsqueda de valores extremos. 

### Patrocinadores (backers)

Esta variable representa al número de patrocinadores que han aportado dinero a la iniciativa.  Vamos a comprobar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$backers)
par(mfrow=c(1,2))
hist(mydata$backers)
boxplot(mydata$backers)
```

Vemos que existen valores muy extremos. El 75% de los datos (3er cuartil) está por debajo de 57 patrocinadores. Sin embargo, existen valores superiores a 200000. Vamos a comprobar a cuantas iniciativas han contribuído más de 100000 personas:
```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
nrow(subset(mydata, backers > 100000))
```

Comprobamos estas observaciones en el set original:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
subset(original, backers > 100000)
```

Acudiendo a Kickstarter, comprobamos que estos valores son correctos, y que se corresponden a las iniciativas que históricamente han tenido más exito en esta plataforma:

* [Fidget Cube: A Vinyl Desk Toy](https://www.kickstarter.com/projects/antsylabs/fidget-cube-a-vinyl-desk-toy?lang=es)
* [https://www.kickstarter.com/projects/elanlee/exploding-kittens?lang=es](https://www.kickstarter.com/projects/antsylabs/fidget-cube-a-vinyl-desk-toy?lang=es)
* [Bring Reading Rainbow Back for Every Child, Everywhere!](https://www.kickstarter.com/projects/readingrainbow/bring-reading-rainbow-back-for-every-child-everywh?lang=es)

Por tanto, son observaciones legítimas que no se deben descartar. Sin embargo, y por intuición, las iniciativas con un número alto de patrocinadores salen adelante. Vamos a identificar la observación con mayor número de patrocinadores que NO ha salido adelante:

```{r echo=TRUE, message=FALSE, warning=FALSE}
aux <- mydata[mydata$state != "successful",]
aux <- aux[order(-aux$backers),]
head(aux, n = 1)
```

Vamos a comprobar cuántas observaciones existen con un mayor número de patrocinadores (y que han salido adelante):

```{r echo=TRUE, message=FALSE, warning=FALSE}
nrow(mydata[mydata$backers > 20632,])
```

Únicamente 79. Esto quiere decir, que imputando el valor 20632 a todas estas observaciones, obtendríamos el mismo resultado y eliminaríamos valores extremos. Sin embargo, para valores inferiores, seguramente la frecuencia de las iniciativas que han tenido éxito es mucho superior al resto de resultados:

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata[mydata$backers > 100,]$state)
tabyl(mydata[mydata$backers > 250,]$state)
tabyl(mydata[mydata$backers > 500,]$state)
tabyl(mydata[mydata$backers > 1000,]$state)
tabyl(mydata[mydata$backers > 2000,]$state)
```

Vemos que a partir de 1000 patrocinadores, la frecuencia de éxito es de prácticamente un 95%. Por tanto, si imputamos el 1000 como valor máximo al número de patrocinadores, conseguiremos eliminar valores extremos manteniendo un resultado prácticamente igual al original. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
nrow(mydata[mydata$backers > 1000,])
mydata <- within(mydata, backers[backers > 1000] <- 1000)
```

Volvemos a comprobar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(mydata$backers)
par(mfrow=c(1,2))
hist(mydata$backers)
boxplot(mydata$backers)
```

Vemos que de esta forma sigue habiendo valores extremos. Sin embargo, esto probablemente se deba a que la distribución no sea normal. Si se aplica la función log, se puede apreciar que ya no existen datos fuera del rango intercuartílico:

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(log(mydata$backers))
par(mfrow=c(1,2))
hist(log(mydata$backers))
boxplot(log(mydata$backers))
```

### Cantidad objetivo (usd_goal_real)

Esta variable representa la cantidad que tienen como objetivo recaudar los proyectos. Vamos a observar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$usd_goal_real)

par(mfrow=c(1,2))
hist(mydata$usd_goal_real)
boxplot(mydata$usd_goal_real)
```

Vemos que en este caso también existen valores extremos. Vamos a comprobar las observaciones asociadas:

```{r echo=TRUE, message=FALSE, warning=FALSE}
aux <- original[order(-original$usd_goal_real),]
head(aux, n = 3)
```

De forma análoga a la variable de _backers_, acudimos a Kickstarter para verificar que, efectivamente, son iniciativas que intentaron recaudar esa cantidad de dinero:

* [FUCK Potato Salad. Paleo Potato Brownies!](https://www.kickstarter.com/projects/2095375022/fuck-potato-salad-lets-bake-potato-brownies?ref=category_location)
* [A Celtic Lovestory](https://www.kickstarter.com/projects/245190432/a-celtic-lovestory?ref=category)
* [Hydroponic's Skyscraper](https://www.kickstarter.com/projects/2099347793/hydroponics-skyscraperun-gratte-ciel-hydroponiquee?ref=category_location)

Dado que aparenemente son proyectos que se crearon como broma, probablemente podemos eliminar valores extremos de la misma forma que hemos hecho con la variable anterior. Vamos a comprobar la frecuencia con de los resultados, filtrando por la cantidad objetivo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata[mydata$usd_goal_real > 100000,]$state)
tabyl(mydata[mydata$usd_goal_real > 1000000,]$state)
tabyl(mydata[mydata$usd_goal_real > 10000000,]$state)
tabyl(mydata[mydata$usd_goal_real > 50000000,]$state)
```

En este caso no observamos un patrón tan significativo como en la variable anterior, por lo que no se realizará la imputación de un valor máximo para evitar la pérdida de información. 

### Cantidad recaudada (usd_pledged_real)

Esta variable es la candidad de dinero recaudado para poder realizar el proyecto. Vamos a comprobar la distribución de los valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$usd_pledged_real)
par(mfrow=c(1,2))
hist(mydata$usd_pledged_real)
boxplot(mydata$usd_pledged_real)
```

Al igual que en el caso anterior, también existen valore extremos (basta con observar la gran diferencia entre la media, la mediana y el valor máximo). Vamos a extraer las observaciones con los valores más altos de eta variable: 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
aux <- original[order(-original$usd_pledged_real),]
head(aux, n = 2)
```

Acudiendo a Kickstarter vemos que estos valores extremos son correctos y se corresponden también a proyectos con mucho éxito. 

* [Pebble Time - Awesome Smartwatch](https://www.kickstarter.com/projects/getpebble/pebble-time-awesome-smartwatch-no-compromises?lang=es)
* [COOLEST COOLER](https://www.kickstarter.com/projects/ryangrepper/coolest-cooler-21st-century-cooler-thats-actually?lang=es)

```{r echo=TRUE, message=FALSE, warning=FALSE}
tabyl(mydata[mydata$usd_pledged_real > 10000,]$state)
tabyl(mydata[mydata$usd_pledged_real > 100000,]$state)

```

A partir de 100000 USD recaudados, el 95% de los proyectos acaban con éxito, por lo que podemos imputar este valor máximo para reducir los valores extremos sin perder apenas información en los datos:

```{r echo=TRUE, message=FALSE, warning=FALSE}
nrow(mydata[mydata$usd_pledged_real > 100000,])
mydata <- within(mydata, usd_pledged_real[usd_pledged_real > 100000] <- 100000)
```

Volvemos a visualizar los datos, y vemos que no parecen ajustarse a una distribución normal:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$usd_pledged_real)

par(mfrow=c(1,2))
hist(mydata$usd_pledged_real)
boxplot(mydata$usd_pledged_real)
```

Sin embargo, en el caso de aplicar el logaritmo, sí que parece que podría tratarse de una distribución LogNormal. 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(log(mydata$usd_pledged_real))

par(mfrow=c(1,2))
hist(log(mydata$usd_pledged_real))
boxplot(log(mydata$usd_pledged_real))
```


### Duración campaña (duration)
Vamos a comprobar la distribución de valores de la variable derivada al inicio:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
summary(mydata$duration)

par(mfrow=c(1,2))
hist(mydata$duration)
boxplot(mydata$duration)
```

Vemos que en este caso también existen valores muy extremos. El valor máximo son 16739 días (45 años), lo que supone que se trata de un valor erróneo. Vamos a comprobar cuantas iniciativas hay con más 100 días de duración:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
nrow(subset(mydata, duration > 100))
```

Únicamente 7, por lo que probablemente se deba a un error en los datos iniciales o en el cálculo de la variable. Para comprobarlo, vamos a examinar las observaciones asociadas en el set de datos inicial:

```{r echo=TRUE, message=FALSE, warning=FALSE}
subset(original, duration > 100)
```

Vemos que el error se debe a que la fecha de inicio de algunas iniciativas está mal informada (1970-01-01). Se trata del valor inicial del formato [epoch](https://en.wikipedia.org/wiki/Unix_time), por lo que seguramente se trate de valores perdidos. Eliminamos estas observaciones, y volvemos a analizar la distribución de valores:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
# Eliminamos observaciones con valores incorrectos
mydata <- subset(mydata, duration < 100)

summary(mydata$duration)

par(mfrow=c(1,2))
hist(mydata$duration)
boxplot(mydata$duration)
```

Vemos que ahora existen valores extremos, pero correctos: la campaña más larga se situa en torno a los 3 meses, mientras que tanto el valor medio como el mediano están en torno a un mes. 

# Análisis de datos

## Análisis de normalidad

En el apartado de valores extremos se ha comprobado a simple vista que las variables no siguen una distribución normal. Sin embargo, dada la forma del histograma es posible que sigan una distribución LogNormal o exponencial. 
Para ello, visualizamos en primer lugar el histograma del logaritmo de estas variables:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
par(mfrow=c(1,2))
hist(log(mydata$backers), main = "Backers")
hist(log(mydata$duration), main = "Duration")
hist(log(mydata$usd_pledged_real), main = "Pledged")
hist(log(mydata$usd_goal_real), main = "Goal")

summary(log(dplyr::select(mydata, backers, duration, usd_pledged_real, usd_goal_real)))
```

Backers y Duration claramente no siguen una distribución LogNormal. Las variables Pledged y Goal, a pesar de tener una forma similar a la de una distribución normal, no se pueden corresponder a una distribución LogNormal por tener valores negativos. 

Dado que a simple vista se puede comprobar que los datos no siguen una distribución normal, no es necesario aplicar el [Test de Shapiro-Wilk](https://es.wikipedia.org/wiki/Test_de_Shapiro%E2%80%93Wilk) ni analizar los diagramas QQ. Tampoco se realizará [la transformación de Box-Cox](https://es.wikipedia.org/wiki/Transformaci%C3%B3n_Box-Cox) al estar los datos muy alejados de una distribución normal, por lo que a la hora de realizar el análisis de los datos se aplicará algoritmos no paramétricos. 

## Selección de datos

Para seleccionar los datos sobre los que vamos a realizar el análisis, vamos a realizar un análisis previo de correlación para ver si es posible reducir la dimensionalidad descartando algunas de las variables que no son independientes.  

Vamos a proceder en primer lugar con las cuatro variables categóricas disponibles. 

En primer lugar, las variables "Category" y "Main Category" están correlacionadas por definición (la primera es un desglose de la segunda). Para realizar un análisis manual, vamos a quedarnos únicamente con la segunda, puesto que la primera tiene un número de valores posibles demasiado alto para ser manejable en un análisis no automatizado.

Por otro lado, las variables "Country" y "Currency" probablemente sean dependientes. Vamos a realizar un 
test [chi-square](https://en.wikipedia.org/wiki/Chi-squared_test) para verificar si se puede obviar una de ellas en el análisis. Planteamos las hipótesis, y supondremos un nivel de significación del 0.05:

$$H_{0}: \text{Las variables son independientes}$$ 

$$H_{1}:  \text{ Las variables NO son independientes}$$

Calculamos el p-value:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
t <- table(mydata$currency, mydata$country)
chisq.test(t ) 
```

Y vemos que el valor es prácticamente 0, por lo que rechazamos la hipótesis nula y aceptamos la alternativa. Esto es, que las variables no son independientes. Por ello, vamos a excluir la variable "Currency" de los datos a analizar.

Para las variables cuantitativas, vamos a calcular la matrix de correlación usando como método la correlación de Spearman, al no distribuirse las variables de forma normal:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
num_vars = dplyr::select(mydata, backers, country, usd_pledged_real, usd_goal_real, duration)
round(cor(x = data.matrix(num_vars), method = "spearman"), 3)
```

Vemos que el número de patrocinadores y el dinero recaudado tienen una relación de correlación positiva, por lo que el análisis se realizará únicamente sobre una de las dos.

Eliminamos del set de datos aquellas variables que no tendremos en cuenta para el análisis:

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
#mydata <- dplyr::select(mydata, -currency, -category, -backers)
```

Por lo que para el análisis dispondremos de 5 variables, y la etiqueta de clase:
```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
glimpse(mydata)
```

## Análisis descriptivo y visual

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
tabyl(mydata$state)
```


## Análisis inferencial
### Análisis de varianza unifactorial 

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
kruskal.test(backers~main_category, data=mydata)

qchisq(.95, df=14)
```

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
ggplot(data = mydata, aes(x=mydata$main_category, y=mydata$usd_pledged_real)) + stat_boxplot(geom ='errorbar') + geom_boxplot(aes(fill=main_category)) + ggtitle("Satisfacción laboral por Sexo") + xlab("Sex") + ylab("Nivel de satisfacción")

```

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE}
ggplot(data = mydata, aes(x=mydata$main_category, y=log(mydata$usd_pledged_real))) + stat_boxplot(geom ='errorbar') + geom_boxplot(aes(fill=main_category)) + ggtitle("Satisfacción laboral por Sexo") + xlab("Sex") + ylab("Nivel de satisfacción")


r <- kruskal.test(log(usd_pledged_real)~main_category, data=mydata)


```



# Representación de resultados

# Conclusión
(Falta completar)

# Referencias y bibliografía
(Falta completar)


